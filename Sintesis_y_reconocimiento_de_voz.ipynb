{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento y síntesis de voz\n",
    "\n",
    "En este notebook veremos como reconocer frases de voz para transcribirlas a texto y viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Requerimientos\n",
    "\n",
    "Para poder seguir correctamente este notebook necesitaremos tener micrófono en nuestro ordenador y las siguientes librerías instaladas:\n",
    "\n",
    "* SpeechRecognition\n",
    "* Pyaudio\n",
    "\n",
    "En caso de no tenerlas instaladas, aquí tienes cómo instalarlas.\n",
    "* SpeechRecognition -->\n",
    "`pip install SpeechRecognition`\n",
    "* Pyaudio -->\n",
    "`conda install pyaudio`\n",
    "`pip install pyttsx3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 1: Reconocimiento de voz\n",
    "\n",
    "En primer lugar vamos a ver cómo reconocer la voz y convertirla a texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de la instalacia de reconocimiento de voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccionar la fuente de audio\n",
    "\n",
    "Como se ha comentado, se puede utilizar el audio desde 2 tipos de fuentes distintas, bien desde un fichero en formato WAV o desde el micrófono, veamos ambos procesos.\n",
    "\n",
    "#### Audio desde fichero\n",
    "\n",
    "El proceso es muy sencillo, bastaría con cargar el archivo utilizando el comando `AudioFile('RUTA_DEL_ARCHIVO')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sr.AudioFile('./example.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar tenemos que cargar el audio del micrófono con el comando `Microphone()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de tener algún error al ejecutar el comando Microphone(), descomentar estas líneas:\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando `Microphone()` seleccionará por defecto el micrófono que nuestro sistema tenga predeterminado, pero podemos seleccionar cualquier otro instalado en el sistema, incluso la salida de audio que podríamos utilizar para transcribir, por ejemplo, una reunión.\n",
    "\n",
    "Para ver la lista de micrófonos ejecutaremos el comando `list_microphone_names()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asignador de sonido Microsoft - Input',\n",
       " 'MicrÃ³fono (Realtek(R) Audio)',\n",
       " 'Asignador de sonido Microsoft - Output',\n",
       " 'Altavoces (Realtek(R) Audio)',\n",
       " 'MSI MP242A (Sonido Intel(R) par',\n",
       " 'Controlador primario de captura de sonido',\n",
       " 'MicrÃ³fono (Realtek(R) Audio)',\n",
       " 'Controlador primario de sonido',\n",
       " 'Altavoces (Realtek(R) Audio)',\n",
       " 'MSI MP242A (Sonido Intel(R) para pantallas)',\n",
       " 'MSI MP242A (Sonido Intel(R) para pantallas)',\n",
       " 'Altavoces (Realtek(R) Audio)',\n",
       " 'MicrÃ³fono (Realtek(R) Audio)',\n",
       " 'Speakers ()',\n",
       " 'MicrÃ³fono ()',\n",
       " 'Mezcla estÃ©reo ()',\n",
       " 'Speakers (Nahimic mirroring Wave Speaker)',\n",
       " 'Output (Sonido Intel(R) para pantallas - Salida 1.1)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone().list_microphone_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar cualquier otro micrónono de la lista basta con especificar el orden que tiene en la lista dentro del comando Micrphone() -> `Microphone(device_index=12)` Seleccionará el 12º de la lista, en este caso \"Micrófono (USB Microphone)\"\n",
    "\n",
    "##### Crear el fragmento de audio\n",
    "\n",
    "Una vez tenemos el input, bien desde audio o desde el micrófono, lo establecemos como source. En este proceso es cuando eliminaríamos el ruido de fondo con el comando `adjust_for_ambient_noise()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_conversion():\n",
    "    with mic as source:\n",
    "        \n",
    "        #Ajustes de sonido ambiente\n",
    "        instance.adjust_for_ambient_noise(source)\n",
    "        \n",
    "        #Comenzar a grabar el audio\n",
    "        audio = instance.listen(source)\n",
    "        \n",
    "        #Transcribir usando la api de google\n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all = True)\n",
    "        \n",
    "        #Devolvemos el resultado obtenido\n",
    "        return transcript ['alternative'][0]['transcript']\n",
    "        \n",
    "def audio_conversion():\n",
    "    with file as source:\n",
    "        \n",
    "        instance.adjust_for_ambient_noise(source)\n",
    "        \n",
    "        audio = instance.record(source)\n",
    "        \n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all = True)\n",
    "        \n",
    "        return transcript ['alternative'][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar las funciones que hemos creado.\n",
    "\n",
    "#### Función de micrófono\n",
    "\n",
    "Cuando ejecutemos el comando, debemos esperar un segundo para empezar a hablar y evitar que se nos corte el principio del audio. La función dejará de grabar automáticamente tras dejar de hablar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el reconocimiento de voz hace referencia a la transcripción de un audio a una cadena de texto mientras que la síntesis de voz es el proceso contrario la conversión en audio de un texto'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de procesamiento de audio\n",
    "\n",
    "Ahora haremos lo mismo con la función del texto. No nos reconocerá el principio del texto, por lo que el reconocimiento no será del todo correcto.\n",
    "\n",
    "El texto contenido en el audio es el siguiente:\n",
    "\n",
    "`La Policía Nacional ha finalizado hoy la implantación de esta nueva versión del DNI y desde hoy únicamente se expedirá este DNI Europeo para todos los ciudadanos españoles.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ha finalizado y la implantación de esta nueva versión del DNI y desde hoy únicamente se expedirá este DNI europeo para todos los ciudadanos españoles'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Síntesis de voz\n",
    "En primer lugar vamos a ver cómo reconocer la voz y convertirla a texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de librerías\n",
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motor de reconocimiento\n",
    "\n",
    "Lo primero que debemos hacer es crear el motor de reconocimiento, para ello basta con ejecutar el comando `init()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración dle motor\n",
    "\n",
    "Una vez creado, toca configurarlo. En nuestro caso, la configuración será estática, puesto que estableceremos el idioma y la velocidad y no necesitaremos modificar habitualmente los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración de la velocidad\n",
    "engine.setProperty('rate', 140)\n",
    "\n",
    "#Configuración del idioma\n",
    "engine.setProperty('voice', 'spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para hablar\n",
    "\n",
    "Ahora solo nos queda crear una función para que nuestro motor hable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def habla(texto):\n",
    "    engine.say(texto)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar la función\n",
    "\n",
    "Ahora solo queda probar la función que hemos creado y escuchar cómo se procesa el texto. Vamos a utilizar el mismo texto para comparar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'La Policía Nacional ha finalizado hoy la implantación de esta nueva versión del DNI y desde hoy únicamente se expedirá este DNI Europeo para todos los ciudadanos españoles.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "habla(texto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
